{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "## 범주형"
      ],
      "metadata": {
        "id": "ztyjbG_Lpjy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAxmO7w3WRld",
        "outputId": "2e965d0b-a904-4d8b-afd0-cb09526cd672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/빅데이터 팀플/dementia_analytics/\""
      ],
      "metadata": {
        "id": "LrRHYktOWUoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### 데이터 로딩 ### \n",
        "\n",
        "# train data loading\n",
        "train_dataset_label = pd.read_csv(path + 'data_processing/dataset_01/training/label/train_dataset_label.csv')\n",
        "train_dataset = pd.read_csv(path + 'data_processing/dataset_01/training/source/train_dataset_remove_nan.csv')\n",
        "\n",
        "# train_output 을 DIAG_NM 하나의 col 만 가지는 data frame으로\n",
        "train_output = pd.merge(train_dataset_label, train_dataset, on='ID')[['DIAG_NM']]\n",
        "\n",
        "# train_input에서 'date' 와 'ID' column 제거\n",
        "train_input = train_dataset.drop(train_dataset.columns[0], axis=1)\n",
        "train_input = train_input.drop(train_input.columns[0], axis=1)\n",
        "\n",
        "# test data loading\n",
        "test_dataset_label = pd.read_csv(path +'data_processing/dataset_01/validation/label/val_dataset_label.csv')\n",
        "test_dataset = pd.read_csv(path +'data_processing/dataset_01/validation/source/val_dataset_remove_nan.csv')\n",
        "\n",
        "# test_output 을 DIAG_NM 하나의 col 만 가지는 data frame으로\n",
        "test_output = pd.merge(test_dataset_label, test_dataset, on='ID')[['DIAG_NM']]\n",
        "\n",
        "# test_input에서 'date' 와 'ID' column 제거 \n",
        "test_input = test_dataset.drop(test_dataset.columns[0], axis=1)\n",
        "test_input = test_input.drop(test_input.columns[0], axis=1)\n",
        "\n",
        "### 레이블 인코딩 ### \n",
        "\n",
        "# 트리 기반 알고리즘에서는 숫자의 크기에 따른 중요도 차이가 없어 레이블 인코딩 OK\n",
        "# 선형적 특징을 가지는 알고리즘들은 one hot encoding 통해 해결해야 함\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 라벨인코더 선언 및 Fitting\n",
        "# CN : 0, Dem : 1, MCI : 2\n",
        "items = ['CN', 'Dem', 'MCI']\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "\n",
        "# train\n",
        "train_output['DIAG_NM'] = encoder.transform(train_output['DIAG_NM'])\n",
        "# display(encoder.classes_)\n",
        "# display(encoder.inverse_transform(train_output['DIAG_NM']))\n",
        "\n",
        "# test\n",
        "test_output['DIAG_NM'] = encoder.transform(test_output['DIAG_NM'])"
      ],
      "metadata": {
        "id": "DHBhW3-OWljd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### RandomForestClassifier ### \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "\n",
        "RF.fit(train_input, train_output)\n",
        "\n",
        "print(RF.score(train_input, train_output))\n",
        "print(RF.score(test_input, test_output)) # 0.6751873071837814"
      ],
      "metadata": {
        "id": "TCb87Sz0nz9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759a6fab-9182-42d7-e3ef-d2d950dbbf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b80fb5c6257e>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  RF.fit(train_input, train_output)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.6791538122520935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### RandomForest GridSearchCV ### \n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params ={\n",
        "    'n_estimators':[10, 100],\n",
        "    'max_depth':[6,8,10,12],\n",
        "    'min_samples_leaf':[8,12,18],\n",
        "    'min_samples_split':[8,16,20]\n",
        "}\n",
        "\n",
        "RF = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "grid_cv = GridSearchCV(RF, param_grid=params, cv=2, n_jobs=-1)\n",
        "grid_cv.fit(train_input, train_output)\n",
        "print(grid_cv.score(train_input, train_output))\n",
        "print(grid_cv.score(test_input, test_output)) # 0.7236668135742618\n",
        "print(grid_cv.best_params_) # {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 10}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB6T9dTqF9Vu",
        "outputId": "bae11a1b-20a8-4692-9e75-fd8fc9dfb035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6510868341029395\n",
            "0.7236668135742618\n",
            "{'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eM6PqRPhYPGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}